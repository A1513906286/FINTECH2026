"""
é˜¿å¸ƒæ‰æ¯”æ¨èæœåŠ¡ - ä½¿ç”¨Ollamaå’ŒDuckDuckGoè‡ªåŠ¨ç”Ÿæˆæ¨è
æ”¹ç¼–è‡ª networked_chat.py
ä½¿ç”¨DuckDuckGo HTMLæœç´¢æ¥å£
"""

import requests
from datetime import datetime
import random
import json
from bs4 import BeautifulSoup
import re


class AbuDhabiService:
    def __init__(self, model_name="llama3.2:3b", use_proxy=True, proxy_url="http://127.0.0.1:7890", ollama_url="http://127.0.0.1:11434"):
        """
        åˆå§‹åŒ–é˜¿å¸ƒæ‰æ¯”æ¨èæœåŠ¡

        å‚æ•°:
            model_name: Ollamaæ¨¡å‹åç§°
            use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†ï¼ˆé»˜è®¤Trueï¼‰
            proxy_url: ä»£ç†åœ°å€ï¼ˆé»˜è®¤Clashä»£ç†ç«¯å£7890ï¼‰
            ollama_url: OllamaæœåŠ¡åœ°å€
        """
        self.model_name = model_name
        self.use_proxy = use_proxy
        self.ollama_url = ollama_url

        # é…ç½®ä»£ç†
        if use_proxy:
            self.proxies = {
                "http": proxy_url,
                "https": proxy_url
            }
            print(f"ğŸŒ å·²å¯ç”¨ä»£ç†: {proxy_url}")
        else:
            self.proxies = None
            print("ğŸŒ æœªä½¿ç”¨ä»£ç†")

        # æµ‹è¯• Ollama è¿æ¥
        try:
            test_url = f"{ollama_url}/api/tags"
            response = requests.get(test_url, timeout=5)
            if response.status_code == 200:
                print(f"âœ… OllamaæœåŠ¡è¿æ¥æˆåŠŸï¼Œæ¨¡å‹: {model_name}")
            else:
                print(f"âš ï¸ OllamaæœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
        except Exception as e:
            print(f"âš ï¸ OllamaæœåŠ¡è¿æ¥å¤±è´¥: {e}")
            print("ğŸ’¡ æç¤º: è¯·ç¡®ä¿Ollamaå·²å®‰è£…å¹¶è¿è¡Œ (ollama serve)")
    
    def translate_to_english(self, chinese_query):
        """
        å°†ä¸­æ–‡æŸ¥è¯¢ç¿»è¯‘æˆè‹±æ–‡ï¼ˆä½¿ç”¨é¢„å®šä¹‰æ˜ å°„ï¼‰
        DuckDuckGo API å¯¹è‹±æ–‡æŸ¥è¯¢æ”¯æŒæ›´å¥½
        """
        translation_map = {
            "é˜¿å¸ƒæ‰æ¯”å¿…å»æ™¯ç‚¹": "Abu Dhabi top attractions",
            "é˜¿å¸ƒæ‰æ¯”ç¾é£Ÿæ¨è": "Abu Dhabi best restaurants",
            "é˜¿å¸ƒæ‰æ¯”è´­ç‰©ä¸­å¿ƒ": "Abu Dhabi shopping malls",
            "é˜¿å¸ƒæ‰æ¯”æ–‡åŒ–ä½“éªŒ": "Abu Dhabi cultural experiences",
            "é˜¿å¸ƒæ‰æ¯”æµ·æ»©åº¦å‡": "Abu Dhabi beach resorts",
            "é˜¿å¸ƒæ‰æ¯”": "Abu Dhabi"
        }

        # æŸ¥æ‰¾æœ€ä½³åŒ¹é…
        for cn_key, en_value in translation_map.items():
            if cn_key in chinese_query:
                return en_value

        # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å› "Abu Dhabi" + åŸæŸ¥è¯¢
        return f"Abu Dhabi {chinese_query}"

    def search_duckduckgo(self, query, num_results=3, timeout=10):
        """
        ä½¿ç”¨DuckDuckGo HTMLæœç´¢æ¥å£è¿›è¡Œæœç´¢ï¼ˆæ”¯æŒä»£ç†ï¼‰
        è‡ªåŠ¨å°†ä¸­æ–‡æŸ¥è¯¢ç¿»è¯‘æˆè‹±æ–‡ä»¥æé«˜æœç´¢æˆåŠŸç‡
        """
        try:
            # æ£€æµ‹æ˜¯å¦ä¸ºä¸­æ–‡æŸ¥è¯¢ï¼Œå¦‚æœæ˜¯åˆ™ç¿»è¯‘æˆè‹±æ–‡
            original_query = query
            if any('\u4e00' <= char <= '\u9fff' for char in query):
                query = self.translate_to_english(query)
                print(f"ğŸŒ ç¿»è¯‘æŸ¥è¯¢: {original_query} -> {query}")

            # ä½¿ç”¨DuckDuckGo HTMLæœç´¢æ¥å£
            url = "https://duckduckgo.com/html/"
            params = {
                "q": query
            }

            # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }

            print(f"ğŸ” æ­£åœ¨æœç´¢: {query}")

            # ä½¿ç”¨ä»£ç†ï¼ˆå¦‚æœå·²é…ç½®ï¼‰
            response = requests.get(
                url,
                params=params,
                headers=headers,
                proxies=self.proxies,  # ä½¿ç”¨ä»£ç†
                timeout=timeout
            )
            response.raise_for_status()

            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []

            # æŸ¥æ‰¾æœç´¢ç»“æœ
            # DuckDuckGo HTMLç‰ˆæœ¬çš„æœç´¢ç»“æœåœ¨ class="result" çš„divä¸­
            result_divs = soup.find_all('div', class_='result')

            for result_div in result_divs[:num_results]:
                try:
                    # æå–æ ‡é¢˜å’Œé“¾æ¥
                    title_tag = result_div.find('a', class_='result__a')
                    if title_tag:
                        title = title_tag.get_text(strip=True)
                        # æå–çœŸå®URLï¼ˆDuckDuckGoä¼šé‡å®šå‘ï¼‰
                        url_link = title_tag.get('href', '')

                        # æ¸…ç†URLï¼ˆç§»é™¤DuckDuckGoçš„é‡å®šå‘ï¼‰
                        if url_link.startswith('//duckduckgo.com/l/?'):
                            # ä»é‡å®šå‘URLä¸­æå–çœŸå®URL
                            match = re.search(r'uddg=([^&]+)', url_link)
                            if match:
                                import urllib.parse
                                url_link = urllib.parse.unquote(match.group(1))

                        if title and url_link:
                            results.append({
                                'title': title[:100],
                                'url': url_link
                            })
                except Exception as e:
                    print(f"âš ï¸ è§£æå•ä¸ªç»“æœå¤±è´¥: {e}")
                    continue

                if len(results) >= num_results:
                    break

            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ç»“æœï¼Œå°è¯•ä½¿ç”¨é€šç”¨çš„ "Abu Dhabi" æŸ¥è¯¢
            if not results and original_query != "Abu Dhabi":
                print(f"âš ï¸ æœªæ‰¾åˆ°ç»“æœï¼Œå°è¯•ä½¿ç”¨é€šç”¨æŸ¥è¯¢: Abu Dhabi")
                return self.search_duckduckgo("Abu Dhabi", num_results, timeout)

            if results:
                print(f"âœ… æœç´¢æˆåŠŸ: {query} - æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
            else:
                print(f"âš ï¸ æœç´¢æœªæ‰¾åˆ°ç»“æœ: {query}")

            return results

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {query} - {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def generate_recommendations(self):
        """
        è‡ªåŠ¨ç”Ÿæˆé˜¿å¸ƒæ‰æ¯”æ¨è
        è¿”å›3æ¡æ¨èä¿¡æ¯
        """
        
        try:
            # å®šä¹‰æ¨èä¸»é¢˜
            topics = [
                "é˜¿å¸ƒæ‰æ¯”å¿…å»æ™¯ç‚¹",
                "é˜¿å¸ƒæ‰æ¯”ç¾é£Ÿæ¨è",
                "é˜¿å¸ƒæ‰æ¯”è´­ç‰©ä¸­å¿ƒ",
                "é˜¿å¸ƒæ‰æ¯”æ–‡åŒ–ä½“éªŒ",
                "é˜¿å¸ƒæ‰æ¯”æµ·æ»©åº¦å‡"
            ]
            
            # éšæœºé€‰æ‹©ä¸€ä¸ªä¸»é¢˜
            topic = random.choice(topics)
            
            # æœç´¢ç›¸å…³ä¿¡æ¯
            print(f"ğŸ” æ­£åœ¨æœç´¢: {topic}")
            search_results = self.search_duckduckgo(topic, num_results=5)
            
            if not search_results:
                return self._get_default_recommendations()
            
            # æ„å»ºæç¤ºè¯
            search_context = "\n".join([
                f"- {r['title']}" for r in search_results[:3]
            ])
            
            system_prompt = """ä½ æ˜¯é˜¿å¸ƒæ‰æ¯”æ—…æ¸¸ä¸“å®¶ã€‚è¯·æ ¹æ®æœç´¢ç»“æœï¼Œç”Ÿæˆ3æ¡ç®€çŸ­çš„é˜¿å¸ƒæ‰æ¯”æ¨èã€‚
æ¯æ¡æ¨èæ ¼å¼ï¼š
1. æ ‡é¢˜ï¼ˆ10-15å­—ï¼‰
2. ç®€ä»‹ï¼ˆ20-30å­—ï¼‰

è¦æ±‚ï¼š
- ç®€æ´æœ‰è¶£
- é€‚åˆæ¸¸å®¢
- çªå‡ºç‰¹è‰²
- ç”¨ä¸­æ–‡å›ç­”"""

            user_prompt = f"""åŸºäºä»¥ä¸‹æœç´¢ç»“æœï¼Œç”Ÿæˆ3æ¡é˜¿å¸ƒæ‰æ¯”æ¨èï¼š

{search_context}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
[
  {{"title": "æ ‡é¢˜1", "description": "ç®€ä»‹1"}},
  {{"title": "æ ‡é¢˜2", "description": "ç®€ä»‹2"}},
  {{"title": "æ ‡é¢˜3", "description": "ç®€ä»‹3"}}
]"""

            # è°ƒç”¨Ollamaç”Ÿæˆæ¨èï¼ˆä½¿ç”¨åŸå§‹HTTPè¯·æ±‚ï¼‰
            print("ğŸ¤– æ­£åœ¨ç”Ÿæˆæ¨è...")

            ollama_api_url = f"{self.ollama_url}/api/chat"
            payload = {
                "model": self.model_name,
                "messages": [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt}
                ],
                "stream": False,
                "options": {
                    'temperature': 0.7,
                    'num_predict': 500
                }
            }

            response = requests.post(
                ollama_api_url,
                json=payload,
                timeout=60
            )
            response.raise_for_status()

            data = response.json()
            ai_response = data.get('message', {}).get('content', '')
            
            # è§£æAIå“åº”
            recommendations = self._parse_ai_response(ai_response, search_results)
            
            print(f"âœ… ç”Ÿæˆäº† {len(recommendations)} æ¡æ¨è")
            return recommendations
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ¨èå¤±è´¥: {str(e)}")
            print(f"âŒ é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            return self._get_default_recommendations()
    
    def _parse_ai_response(self, ai_response, search_results):
        """è§£æAIå“åº”ï¼Œæå–æ¨èä¿¡æ¯"""
        try:
            import json
            import re
            
            # å°è¯•æå–JSON
            json_match = re.search(r'\[.*\]', ai_response, re.DOTALL)
            if json_match:
                recommendations_data = json.loads(json_match.group())
                
                # ç»„åˆAIç”Ÿæˆçš„æ ‡é¢˜å’Œæœç´¢ç»“æœçš„é“¾æ¥
                recommendations = []
                for i, item in enumerate(recommendations_data[:3]):
                    rec = {
                        'title': item.get('title', f'æ¨è {i+1}'),
                        'description': item.get('description', ''),
                        'url': search_results[i]['url'] if i < len(search_results) else '#',
                        'icon': self._get_icon_for_index(i)
                    }
                    recommendations.append(rec)
                
                return recommendations
        except:
            pass
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨æœç´¢ç»“æœ
        return self._format_search_results(search_results)
    
    def _format_search_results(self, search_results):
        """æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºæ¨èæ ¼å¼"""
        recommendations = []
        for i, result in enumerate(search_results[:3]):
            recommendations.append({
                'title': result['title'][:30],
                'description': 'ç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…',
                'url': result['url'],
                'icon': self._get_icon_for_index(i)
            })
        return recommendations
    
    def _get_icon_for_index(self, index):
        """æ ¹æ®ç´¢å¼•è¿”å›å›¾æ ‡emoji"""
        icons = ['ğŸ›ï¸', 'ğŸ–ï¸', 'ğŸ½ï¸', 'ğŸ›ï¸', 'ğŸ¨', 'ğŸ•Œ']
        return icons[index % len(icons)]
    
    def _get_default_recommendations(self):
        """è¿”å›é»˜è®¤æ¨èï¼ˆå½“Ollamaä¸å¯ç”¨æ—¶ï¼‰"""
        return [
            {
                'title': 'é˜¿å¸ƒæ‰æ¯”8å¤§å¿…æ¸¸æ™¯ç‚¹ç›˜ç‚¹',
                'description': 'æ¢ç´¢é˜¿å¸ƒæ‰æ¯”æœ€å—æ¬¢è¿çš„æ—…æ¸¸æ™¯ç‚¹',
                'url': 'https://www.mafengwo.cn/gonglve/ziyouxing/267891.html',
                'icon': 'ğŸ›ï¸'
            },
            {
                'title': 'Abu Dhabi Mall',
                'description': 'é˜¿å¸ƒæ‰æ¯”æœ€å¤§çš„è´­ç‰©ä¸­å¿ƒ',
                'url': 'https://www.abudhabimall.com',
                'icon': 'ğŸ›ï¸'
            },
            {
                'title': '10 å¤§é˜¿å¸ƒæ‰æ¯”æœ€ä½³ç¾é£Ÿé¤å… (2025)',
                'description': 'å“å°åœ°é“çš„é˜¿è”é…‹ç¾é£Ÿ',
                'url': 'https://www.tripadvisor.cn/Restaurants-g295424-Abu_Dhabi.html',
                'icon': 'ğŸ½ï¸'
            }
        ]

